{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ca13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import urllib\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear \n",
    "\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "# import random\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be95c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def tensor_from_numpy(x, device):\n",
    "    return torch.from_numpy(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb24943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class HalfAutoEncoder(nn.Module):\n",
    "    def __init__(self,linear5,linear6,linear7,linear8 ):\n",
    "        super(HalfAutoEncoder,self).__init__()\n",
    "         \n",
    "        self.linear5= linear5\n",
    "        self.linear6= linear6\n",
    "        self.linear7= linear7\n",
    "        self.linear8= linear8\n",
    "    \n",
    "    def forward(self, h4):\n",
    "        self.h5  = F.relu(self.linear5( h4))\n",
    "        self.h5 = F.normalize(self.h5)\n",
    "        \n",
    "        self.h6  = F.sigmoid(self.linear6( self.h5))\n",
    "        self.h6 = F.normalize(self.h6)\n",
    "        \n",
    "        self.h7  = F.relu(self.linear7(self.h6))\n",
    "        self.h7 = F.normalize(self.h7)\n",
    "        \n",
    "        self.h8  = self.linear8(self.h7)\n",
    "\n",
    "        return  self.h8\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac26805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数定义\n",
    "LEARNING_RATE = 0\n",
    "WEIGHT_DACAY = 0\n",
    "EPOCHS = 1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "249b4d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.HalfAutoEncoder"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_np = np.load(\"../model/feacture_np.npy\")\n",
    " \n",
    "tensor_x = tensor_from_numpy(feature_np , DEVICE)\n",
    "\n",
    "model = torch.load( '../model/half_auto_encoder.pt', map_location=torch.device('cpu'))\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cf4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature = np.load('../data/X_np/X.npy')\n",
    "node_feature2= np.zeros(shape=[850,1879],dtype=np.float32)\n",
    "node_feature2[:,0:256]=node_feature[:, 0:256]\n",
    "\n",
    "for i in range(0,850):\n",
    "    for j in range(0,1623):\n",
    "        try:\n",
    "            node_feature2[i][j+256]=max(node_feature[i,256+5*j: 256+j*5+5]) \n",
    "        except:\n",
    "            print(j)\n",
    "            break\n",
    "            \n",
    "node_feature2/=node_feature2.sum(1, keepdims=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475523c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_y = tensor_from_numpy(node_feature2, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f05f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义：Model, Loss, Optimizer\n",
    "\n",
    "criterion=nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=LEARNING_RATE, \n",
    "                       weight_decay=WEIGHT_DACAY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd4e601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_train_mask=[False  for i in range(0,850)]\n",
    "tensor_train_mask[1]=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e21504e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroOneEncoder():\n",
    "    def __init__(self,model,tensor_x, tensor_y):\n",
    "        self.model=model\n",
    "        self.tensor_x=tensor_x\n",
    "        self.tensor_mask=self.tensor_x\n",
    "        self.tensor_y=tensor_y\n",
    "        self.zero_one_feature=np.zeros(shape=tensor_x.shape)\n",
    "        self.tensor_train_mask=[False  for i in range(0,850)]\n",
    "        self.criterion=nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    def run(self):\n",
    "#         for i in range(0,tensor_x.shape[0]):\n",
    "        for i in range(0,5):\n",
    "            \n",
    "            self.tensor_train_mask[i]=True # 一次只取一条数据出来计算loss\n",
    "            \n",
    "            logits = self.model(self.tensor_x)  # 前向传播\n",
    "            train_mask_logits = logits[self.tensor_train_mask]   # 只选择训练节点进行监督\n",
    "            loss = self.criterion(train_mask_logits, tensor_y[tensor_train_mask])  #计算每一条数据的loss\n",
    "            \n",
    "            # 对每一条数据的特征一个个进行mask,看看哪个特征被mask以后引起loss剧烈变化,就置为1, 否则置为0\n",
    "\n",
    "            for j in range(0,self.tensor_x.shape[1]):\n",
    "                 \n",
    "                self.tensor_mask[i][j]=0 #对第i条数据的第j 个特征进行 mask\n",
    "                logits = self.model(self.tensor_mask)  # 前向传播\n",
    "                train_mask_logits = logits[self.tensor_train_mask]   # 只选择训练节点进行监督\n",
    "                mask_loss = self.criterion(train_mask_logits, tensor_y[tensor_train_mask])   #计算每一条数据的loss\n",
    "                print( 'ok: ',abs(mask_loss.item()-loss.item())/loss.item() )\n",
    "                if  abs(mask_loss.item()-loss.item())/loss.item() >6e-5:\n",
    "#                     print( 'ok: ',mask_loss.item()-loss.item() )\n",
    "                    self.zero_one_feature[i][j]=1\n",
    "                \n",
    "                self.tensor_mask[i][j]=self.tensor_x[i][j] #把被mask的地方还原回来\n",
    "                \n",
    "            self.tensor_train_mask[i]=False\n",
    "            print(\"=====================\")\n",
    "            \n",
    "        return self.zero_one_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df9b3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_encoder=ZeroOneEncoder(model,tensor_x, tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee706ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok:  1.3198854999328808e-05\n",
      "ok:  8.78173818421252e-05\n",
      "ok:  0.00014428748306084447\n",
      "ok:  2.4372885652169674e-05\n",
      "ok:  5.9844808462865845e-05\n",
      "ok:  4.6495966474908304e-05\n",
      "ok:  6.141967184346758e-05\n",
      "ok:  5.107056962808476e-05\n",
      "ok:  1.5898620794646065e-05\n",
      "ok:  6.824407982607509e-06\n",
      "ok:  2.3847931191969098e-05\n",
      "ok:  2.7672599402001878e-05\n",
      "=====================\n",
      "ok:  1.3198854999328808e-05\n",
      "ok:  8.819234931369704e-05\n",
      "ok:  0.0001442124895665301\n",
      "ok:  2.4372885652169674e-05\n",
      "ok:  5.9844808462865845e-05\n",
      "ok:  4.702092093510888e-05\n",
      "ok:  6.186963280935379e-05\n",
      "ok:  5.107056962808476e-05\n",
      "ok:  1.5898620794646065e-05\n",
      "ok:  6.824407982607509e-06\n",
      "ok:  2.3847931191969098e-05\n",
      "ok:  2.7672599402001878e-05\n",
      "=====================\n",
      "ok:  1.312386150501444e-05\n",
      "ok:  8.819234931369704e-05\n",
      "ok:  0.0001442124895665301\n",
      "ok:  2.444787914648404e-05\n",
      "ok:  6.014478244012332e-05\n",
      "ok:  4.657095996922267e-05\n",
      "ok:  6.194462630366816e-05\n",
      "ok:  5.099557613377039e-05\n",
      "ok:  1.5973614288960432e-05\n",
      "ok:  6.824407982607509e-06\n",
      "ok:  2.3847931191969098e-05\n",
      "ok:  2.7672599402001878e-05\n",
      "=====================\n",
      "ok:  1.3348841987957544e-05\n",
      "ok:  8.819234931369704e-05\n",
      "ok:  0.0001442124895665301\n",
      "ok:  2.4672859629427147e-05\n",
      "ok:  5.9769814968551475e-05\n",
      "ok:  4.657095996922267e-05\n",
      "ok:  6.186963280935379e-05\n",
      "ok:  5.099557613377039e-05\n",
      "ok:  1.5973614288960432e-05\n",
      "ok:  6.899401476921877e-06\n",
      "ok:  2.3847931191969098e-05\n",
      "ok:  2.7672599402001878e-05\n",
      "=====================\n",
      "ok:  1.357382247090065e-05\n",
      "ok:  8.819234931369704e-05\n",
      "ok:  0.0001442124895665301\n",
      "ok:  2.4672859629427147e-05\n",
      "ok:  5.9844808462865845e-05\n",
      "ok:  4.702092093510888e-05\n",
      "ok:  6.186963280935379e-05\n",
      "ok:  5.107056962808476e-05\n",
      "ok:  1.5898620794646065e-05\n",
      "ok:  6.899401476921877e-06\n",
      "ok:  2.3847931191969098e-05\n",
      "ok:  2.7672599402001878e-05\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "zero_one_feature=zero_one_encoder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04c76e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_one_feature[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ce9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_np.shape\n",
    "from scipy.spatial import distance\n",
    "a = (1, 2, 3)\n",
    "b = (4, 5, 6)\n",
    "dst = distance.euclidean(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc60efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_adj=np.zeros(shape=[850,850])\n",
    "for i in range(0,850):\n",
    "    for j in range(i+1,850):\n",
    "        np_adj[i][j]=distance.euclidean(feature_np[i], feature_np[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "for i in range(1,850):\n",
    "    for j in range(0,i):\n",
    "        np_adj[i][j]=np_adj[j][i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1139a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "np_adj/=np_adj.sum(1, keepdims=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import markov_clustering as mc\n",
    " \n",
    " \n",
    " \n",
    "matrix =sp.csr_matrix(np_adj)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c933ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mc.run_mcl(matrix,inflation=10)           # run MCL with default parameters\n",
    "clusters = mc.get_clusters(result)    # get clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26648c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be032605",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inflation in [i / 10 for i in range(15, 26)]:\n",
    "    result = mc.run_mcl(matrix, inflation=inflation)\n",
    "    clusters = mc.get_clusters(result)\n",
    "    Q = mc.modularity(matrix=result, clusters=clusters)\n",
    "    print(\"inflation:\", inflation, \"modularity:\", Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9db63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numnodes = 3\n",
    "\n",
    "# generate random positions as a dictionary where the key is the node id and the value\n",
    "# is a tuple containing 2D coordinates\n",
    "positions = {i:(random.random() * 2 - 1, random.random() * 2 - 1) for i in range(numnodes)}\n",
    "\n",
    "# use networkx to generate the graph\n",
    "network = nx.random_geometric_graph(numnodes, 0.3, pos=positions)\n",
    "\n",
    "# then get the adjacency matrix (in sparse form)\n",
    "matrix = nx.to_scipy_sparse_matrix(network)\n",
    "matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca7e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
